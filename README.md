\# ETL â€“ DÃ­a 1 | IntegraciÃ³n de Datos con Python y SQLite



\## ğŸ“Œ Contexto

Este proyecto corresponde al DÃ­a 1 de la semana 4 del curso de AnÃ¡lisis de Datos,

enfocado en el diseÃ±o conceptual y prÃ¡ctico de un pipeline ETL (Extract, Transform, Load).



El objetivo es integrar datos provenientes de distintos sistemas de una cadena de tiendas

minoristas para generar una fuente de datos unificada y lista para anÃ¡lisis analÃ­tico.



---



\## ğŸª Escenario de Negocio

Una cadena de tiendas minoristas desea integrar informaciÃ³n desde:



\- Sistema de Punto de Venta (POS)

\- Sistema de Inventario

\- CRM de clientes

\- Sitio web (analÃ­tica digital)



Los datos se encuentran fragmentados, en distintos formatos y con diferentes frecuencias

de actualizaciÃ³n.



---



\## ğŸ› ï¸ TecnologÃ­as Utilizadas

\- Python 3

\- Pandas

\- SQLite

\- Jupyter Notebook

\- Git



---



\## ğŸ”„ Proceso ETL



\### Extract

\- Datos de ventas simulados (POS)

\- InformaciÃ³n de clientes simulada (CRM)

\- Datos de analÃ­tica web simulados (no persistidos en este ejercicio)



\### Transform

\- ConversiÃ³n de marcas de tiempo a fechas

\- EliminaciÃ³n de registros duplicados

\- CÃ¡lculo de mÃ©tricas (total de venta)

\- Enriquecimiento de ventas con segmento de cliente

\- NormalizaciÃ³n de columnas



\### Load

\- Carga de los datos transformados en una base de datos SQLite

\- CreaciÃ³n de la tabla `ventas\_consolidadas`

\- ExportaciÃ³n de resultados finales a Excel para validaciÃ³n y visualizaciÃ³n





---



\## ğŸ“Š Resultado Final

Se generÃ³ una base de datos SQLite (`ventas\_etl.db`) con una tabla consolidada de ventas,

verificada tanto desde Python como mediante consultas SQL directas.



La tabla final contiene informaciÃ³n limpia, consistente y lista para anÃ¡lisis.



---



\## âœ… ConclusiÃ³n

Este ejercicio demuestra la implementaciÃ³n completa de un pipeline ETL real,

utilizando Python como orquestador del proceso y SQLite como sistema de almacenamiento,

siguiendo buenas prÃ¡cticas de integraciÃ³n y calidad de datos.

---

## â–¶ï¸ CÃ³mo ejecutar el proyecto

1. Activar el entorno virtual
2. Abrir Jupyter Notebook
3. Ejecutar el archivo `ETL_Semana4_Dia1.ipynb` de arriba hacia abajo
4. La base de datos `ventas_etl.db` y el archivo `ventas_consolidadas.xlsx`
   se generan automÃ¡ticamente


```

analisis-datos-ETL/

â”‚

â”œâ”€â”€ dia1\_etl\_pipeline.ipynb

â”œâ”€â”€ ventas\_etl.db

â”œâ”€â”€ ventas\_consolidadas.xlsx

â”œâ”€â”€ README.md

â””â”€â”€ .gitignore

```

